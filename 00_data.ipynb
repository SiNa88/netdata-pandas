{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "\n",
    "> Read data from netdata rest api into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# export\n",
    "import asks\n",
    "import trio\n",
    "import pandas as pd\n",
    "import requests\n",
    "from netdata_pandas.wrangle import drop_low_uniqueness_cols, drop_low_std_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_chart_list(host: str = '127.0.0.1:19999', starts_with: str = None) -> list:\n",
    "    \"\"\"Get list of all available charts on a `host`.  \n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **host** `str` The host we want to get a list of available charts from.\n",
    "    - **starts_with** `str` A string to filter the list of charts returns to just those that start with `starts_with`.\n",
    "    \n",
    "    ##### Returns:  \n",
    "    - **chart_list** `list` A list of availalbe charts.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"http://{host}/api/v1/charts\"\n",
    "    r = requests.get(url)\n",
    "    charts = r.json().get('charts')\n",
    "    chart_list = [chart for chart in charts]\n",
    "    if starts_with:\n",
    "        chart_list = [chart for chart in chart_list if chart.startswith(starts_with)]\n",
    "    return chart_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "# get some charts from london demo site\n",
    "charts = get_chart_list('london.my-netdata.io', starts_with='system.')\n",
    "\n",
    "# check just system. charts returned\n",
    "assert set([chart.split('.')[0] for chart in charts]) == set(['system'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "async def get_chart(api_call: str, data: list, col_sep: str ='|'):\n",
    "    \"\"\"Get data for an individual chart.\n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **api_call** `tuple` A tuple of (`url`,`chart`) for the url to pull data from and chart it represents.\n",
    "    - **data** `list` A list for dataframes for each chart to be appended to.\n",
    "    - **col_sep** `str` A character for separating chart and dimension in column names of dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url, chart, host = api_call\n",
    "    r = await asks.get(url)\n",
    "    r_json = r.json()\n",
    "    df = pd.DataFrame(r_json['data'], columns=['time_idx'] + r_json['labels'][1:])\n",
    "    df['host'] = host\n",
    "    df = df.set_index(['host','time_idx']).add_prefix(f'{chart}{col_sep}')\n",
    "    data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "async def get_charts(api_calls: list, col_sep: str ='|', timeout: int = 60) -> pd.DataFrame:\n",
    "    \"\"\"Create a nursey to make seperate async calls to get each chart.\n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **api_calls** `list` A list of tuple's of [(`url`,`chart`),...] of api calls that need to be made.\n",
    "    - **col_sep** `str` A character for separating chart and dimension in column names of dataframe.\n",
    "    - **timeout** `int` The number of seconds for trio to [move_on_after](https://trio.readthedocs.io/en/stable/reference-core.html#trio.move_on_after).\n",
    "    \n",
    "    ##### Returns:  \n",
    "    - **df** `pd.DataFrame` A pandas dataframe with all chart data outer joined based on time index.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    with trio.move_on_after(timeout):\n",
    "        async with trio.open_nursery() as nursery:\n",
    "            for api_call in api_calls:\n",
    "                nursery.start_soon(get_chart, api_call, data, col_sep)\n",
    "    df = pd.concat(data, join='outer', axis=1, sort=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_data(hosts: list = ['london.my-netdata.io'], charts: list = ['system.cpu'], after: int = -60, \n",
    "             before: int = 0, points: int = 0, col_sep: str = '|', numeric_only: bool = False,\n",
    "             ffill: bool = True, diff: bool = False, timeout: int = 60, nunique_thold = None, \n",
    "             std_thold: float = None, index_as_datetime: bool = False, freq: str = 'infer') -> pd.DataFrame:\n",
    "    \"\"\"Define api calls to make and any post processing to be done.\n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **hosts** `list` A list of hosts to pull data from.\n",
    "    - **charts** `list` A list of charts to pull data for.\n",
    "    - **after** `int` The timestamp or relative integer from which to pull data after.\n",
    "    - **before** `int` The timestamp or relative integer from which to pull data before.\n",
    "    - **points** `int` The `points` parameter to pass to the api call if need to aggregate data in some way.\n",
    "    - **col_sep** `str` A character for separating chart and dimension in column names of dataframe.\n",
    "    - **numeric_only** `bool` Set to true if you want to filter out any non numeric data.\n",
    "    - **ffill** `bool` Set to true if you want to forward fill any null or missing values.\n",
    "    - **diff** `bool` Set to true if you want to get the difference of metrics as opposed to their raw value.\n",
    "    - **timeout** `int` The number of seconds for trio to [move_on_after](https://trio.readthedocs.io/en/stable/reference-core.html#trio.move_on_after).\n",
    "    - **nunique_thold** [`float`,`int`] If defined calls function to filter cols with low number of unique values.\n",
    "    - **std_thold** `float` If defined calls function to filter cols with low standard deviation.\n",
    "    - **index_as_datetime** `bool` If true, set the index to be a pandas datetime.\n",
    "    - **freq** `str` Freq to be passed to pandas datetime index.\n",
    "    \n",
    "        \n",
    "    ##### Returns:  \n",
    "    - **df** `pd.DataFrame` A pandas dataframe with all chart data outer joined based on time index and any post processing done.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # if hosts is a string make it a list of one\n",
    "    if isinstance(hosts, str):\n",
    "        hosts = [hosts]\n",
    "        \n",
    "    # if charts is a string make it a list of one\n",
    "    if isinstance(charts, str):\n",
    "        # if specified get all charts\n",
    "        if charts == 'all':\n",
    "            charts = get_chart_list(hosts[0])\n",
    "        else:\n",
    "            charts = [charts]\n",
    "        \n",
    "    \n",
    "    # define list of all api calls to be made\n",
    "    api_calls = [\n",
    "        (f'http://{host}/api/v1/data?chart={chart}&after={after}&before={before}&points={points}&format=json', chart, host)\n",
    "        for host in hosts for chart in charts\n",
    "    ] \n",
    "    # get the data\n",
    "    df = trio.run(get_charts, api_calls, col_sep, timeout)\n",
    "    # post process the data\n",
    "    if len(hosts) == 1:\n",
    "        df = df.reset_index(level=0, drop=True)\n",
    "    if numeric_only:\n",
    "        df = df._get_numeric_data()\n",
    "    if ffill:\n",
    "        df = df.ffill()\n",
    "    if diff:\n",
    "        df = df.diff().dropna(how='all')\n",
    "    if nunique_thold:\n",
    "        df = drop_low_uniqueness_cols(df, nunique_thold)\n",
    "    if std_thold:\n",
    "        df = drop_low_std_cols(df, std_thold)\n",
    "    if index_as_datetime:\n",
    "        df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df.index, unit='s'), freq=freq))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(64, 554)\n            disk_mops.vda|writes  netdata.requests|requests  system.io|out  \\\ntime_idx                                                                     \n1600946595                   NaN                        NaN            NaN   \n1600946596              0.000000                  23.293680      -10.76060   \n1600946597              0.000000                  20.323980       -5.23940   \n1600946598              0.000000                   8.903625        0.00000   \n1600946599             -5.390782                   3.326795      -26.95286   \n\n            netdata.server_cpu|user  netdata.server_cpu|system  \\\ntime_idx                                                         \n1600946595                      NaN                        NaN   \n1600946596                13.287540                   9.293180   \n1600946597                17.394410                   2.620197   \n1600946598                 9.230359                   8.083418   \n1600946599                 9.390573                   3.916582   \n\n            netdata.queries|queries  services.mem_usage|nginx  \\\ntime_idx                                                        \n1600946595                      NaN                       NaN   \n1600946596                16.975970                 13.398438   \n1600946597                17.012430                 13.519531   \n1600946598                 5.555713                 13.398438   \n1600946599                 0.000000                 13.519531   \n\n            services.mem_usage|netdata  services.mem_usage|mariadb  \\\ntime_idx                                                             \n1600946595                         NaN                         NaN   \n1600946596                    2218.508                    63.83594   \n1600946597                    2216.363                    63.84766   \n1600946598                    2216.559                    63.84766   \n1600946599                    2216.383                    63.84766   \n\n            netdata.db_points|read  ...  apps.uptime|time  apps.uptime|named  \\\ntime_idx                            ...                                        \n1600946595                     NaN  ...               NaN                NaN   \n1600946596               24429.630  ...               NaN                NaN   \n1600946597               23717.330  ...               NaN                NaN   \n1600946598                7745.365  ...        60082600.0         60082600.0   \n1600946599                   0.000  ...        60082600.0         60082600.0   \n\n            apps.uptime|cron  apps.uptime|ksmd  apps.uptime|system  \\\ntime_idx                                                             \n1600946595               NaN               NaN                 NaN   \n1600946596               NaN               NaN                 NaN   \n1600946597               NaN               NaN                 NaN   \n1600946598        60082600.0        60082600.0          60082600.0   \n1600946599        60082600.0        60082600.0          60082600.0   \n\n            apps.uptime|kernel  apps.uptime|other  \\\ntime_idx                                            \n1600946595                 NaN                NaN   \n1600946596                 NaN                NaN   \n1600946597                 NaN                NaN   \n1600946598          60082600.0         60082600.0   \n1600946599          60082600.0         60082600.0   \n\n            mysql_local.queries|queries  mysql_local.queries|questions  \\\ntime_idx                                                                 \n1600946595                          NaN                            NaN   \n1600946596                          NaN                            NaN   \n1600946597                          NaN                            NaN   \n1600946598                          NaN                            NaN   \n1600946599                     4.000374                       4.000374   \n\n            nginx_local.requests|requests  \ntime_idx                                   \n1600946595                            NaN  \n1600946596                            NaN  \n1600946597                            NaN  \n1600946598                            NaN  \n1600946599                       7.965186  \n\n[5 rows x 554 columns]\n"
    }
   ],
   "source": [
    "# examples\n",
    "\n",
    "df = get_data('london.my-netdata.io', 'all', after=-60, before=0, nunique_thold=0.05)\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "# get some test data\n",
    "test_host = 'london.my-netdata.io'\n",
    "test_charts = ['system.cpu', 'system.load']\n",
    "df = get_data(test_host, test_charts, after=-60, before=0, col_sep='|')\n",
    "\n",
    "# look for some expected columns\n",
    "assert 'system.load|load1' in df.columns\n",
    "assert 'system.cpu|user' in df.columns\n",
    "# check expected shape of data\n",
    "assert str(df.shape) == '(60, 12)' or '(61, 12)'\n",
    "# check that all types are float64 or int64\n",
    "assert len(df.dtypes[df.dtypes != 'int64'][df.dtypes != 'float64']) == 0\n",
    "\n",
    "# test index as datetime\n",
    "df = get_data('london.my-netdata.io', 'system.cpu', index_as_datetime=True)\n",
    "assert isinstance(df.index, pd.core.indexes.datetimes.DatetimeIndex)\n",
    "assert isinstance(df.index.freq, pd.tseries.offsets.Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_alarm_log(host: str = '127.0.0.1:19999', datetimes: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Get alarm log from `host`.  \n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **host** `str` The host we want to get the alarm log from.\n",
    "    \n",
    "    ##### Returns:  \n",
    "    - **df** `pd.DataFrame` A df of the alarm_log.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"http://{host}/api/v1/alarm_log\"\n",
    "    r = requests.get(url)\n",
    "    alarm_log = r.json()\n",
    "    df = pd.DataFrame(alarm_log)\n",
    "    if datetimes:\n",
    "        for col in ['when', 'delay_up_to_timestamp']:\n",
    "            df[col] = pd.to_datetime(df[col], unit='s')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests \n",
    "\n",
    "df = get_alarm_log('london.my-netdata.io')\n",
    "\n",
    "expected_cols = ['hostname', 'unique_id', 'alarm_id', 'alarm_event_id', 'name', 'chart', 'family', 'processed', 'updated', 'exec_run', 'exec_failed', 'exec', 'recipient', 'exec_code', 'source', 'units', 'when', 'duration', 'non_clear_duration', 'status', 'old_status', 'delay', 'delay_up_to_timestamp', 'updated_by_id', 'updates_id', 'value_string', 'old_value_string', 'last_repeat', 'silenced', 'info', 'value', 'old_value', 'no_clear_notification']\n",
    "\n",
    "assert list(df.columns) == expected_cols\n",
    "assert len(df) >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
