{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "\n",
    "> Read data from netdata rest api into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# export\n",
    "import asks\n",
    "import trio\n",
    "import pandas as pd\n",
    "import requests\n",
    "from netdata_pandas.wrangle import drop_low_uniqueness_cols, drop_low_std_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_chart_list(host: str = '127.0.0.1:19999', starts_with: str = None) -> list:\n",
    "    \"\"\"Get list of all available charts on a `host`.  \n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **host** `str` The host we want to get a list of available charts from.\n",
    "    - **starts_with** `str` A string to filter the list of charts returns to just those that start with `starts_with`.\n",
    "    \n",
    "    ##### Returns:  \n",
    "    - **chart_list** `list` A list of availalbe charts.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"http://{host}/api/v1/charts\"\n",
    "    r = requests.get(url)\n",
    "    charts = r.json().get('charts')\n",
    "    chart_list = [chart for chart in charts]\n",
    "    if starts_with:\n",
    "        chart_list = [chart for chart in chart_list if chart.startswith(starts_with)]\n",
    "    return chart_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "# get some charts from london demo site\n",
    "charts = get_chart_list('london.my-netdata.io', starts_with='system.')\n",
    "\n",
    "# check just system. charts returned\n",
    "assert set([chart.split('.')[0] for chart in charts]) == set(['system'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "async def get_chart(api_call: str, data: list, col_sep: str ='|'):\n",
    "    \"\"\"Get data for an individual chart.\n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **api_call** `tuple` A tuple of (`url`,`chart`) for the url to pull data from and chart it represents.\n",
    "    - **data** `list` A list for dataframes for each chart to be appended to.\n",
    "    - **col_sep** `str` A character for separating chart and dimension in column names of dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url, chart, host = api_call\n",
    "    r = await asks.get(url)\n",
    "    r_json = r.json()\n",
    "    df = pd.DataFrame(r_json['data'], columns=['time_idx'] + r_json['labels'][1:])\n",
    "    df['host'] = host\n",
    "    df = df.set_index(['host','time_idx']).add_prefix(f'{chart}{col_sep}')\n",
    "    data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "async def get_charts(api_calls: list, col_sep: str ='|', timeout: int = 60) -> pd.DataFrame:\n",
    "    \"\"\"Create a nursey to make seperate async calls to get each chart.\n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **api_calls** `list` A list of tuple's of [(`url`,`chart`),...] of api calls that need to be made.\n",
    "    - **col_sep** `str` A character for separating chart and dimension in column names of dataframe.\n",
    "    - **timeout** `int` The number of seconds for trio to [move_on_after](https://trio.readthedocs.io/en/stable/reference-core.html#trio.move_on_after).\n",
    "    \n",
    "    ##### Returns:  \n",
    "    - **df** `pd.DataFrame` A pandas dataframe with all chart data outer joined based on time index.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    with trio.move_on_after(timeout):\n",
    "        async with trio.open_nursery() as nursery:\n",
    "            for api_call in api_calls:\n",
    "                nursery.start_soon(get_chart, api_call, data, col_sep)\n",
    "    df = pd.concat(data, join='outer', axis=1, sort=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_data(hosts: list = ['london.my-netdata.io'], charts: list = ['system.cpu'], after: int = -60, \n",
    "             before: int = 0, points: int = 0, col_sep: str = '|', numeric_only: bool = False,\n",
    "             ffill: bool = True, diff: bool = False, timeout: int = 60, nunique_thold = None, \n",
    "             std_thold: float = None, index_as_datetime: bool = False, freq: str = 'infer', \n",
    "             group: str = 'average', sort_cols: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Define api calls to make and any post processing to be done.\n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **hosts** `list` A list of hosts to pull data from.\n",
    "    - **charts** `list` A list of charts to pull data for.\n",
    "    - **after** `int` The timestamp or relative integer from which to pull data after.\n",
    "    - **before** `int` The timestamp or relative integer from which to pull data before.\n",
    "    - **points** `int` The `points` parameter to pass to the api call if need to aggregate data in some way.\n",
    "    - **col_sep** `str` A character for separating chart and dimension in column names of dataframe.\n",
    "    - **numeric_only** `bool` Set to true if you want to filter out any non numeric data.\n",
    "    - **ffill** `bool` Set to true if you want to forward fill any null or missing values.\n",
    "    - **diff** `bool` Set to true if you want to get the difference of metrics as opposed to their raw value.\n",
    "    - **timeout** `int` The number of seconds for trio to [move_on_after](https://trio.readthedocs.io/en/stable/reference-core.html#trio.move_on_after).\n",
    "    - **nunique_thold** [`float`,`int`] If defined calls function to filter cols with low number of unique values.\n",
    "    - **std_thold** `float` If defined calls function to filter cols with low standard deviation.\n",
    "    - **index_as_datetime** `bool` If true, set the index to be a pandas datetime.\n",
    "    - **freq** `str` Freq to be passed to pandas datetime index.\n",
    "    - **group** `str` The grouping function to use.\n",
    "    - **sort_cols** `bool` True to sort columns by name.\n",
    "    \n",
    "        \n",
    "    ##### Returns:  \n",
    "    - **df** `pd.DataFrame` A pandas dataframe with all chart data outer joined based on time index and any post processing done.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # if hosts is a string make it a list of one\n",
    "    if isinstance(hosts, str):\n",
    "        hosts = [hosts]\n",
    "        \n",
    "    # if charts is a string make it a list of one\n",
    "    if isinstance(charts, str):\n",
    "        # if specified get all charts\n",
    "        if charts == 'all':\n",
    "            charts = get_chart_list(hosts[0])\n",
    "        else:\n",
    "            charts = [charts]\n",
    "        \n",
    "    \n",
    "    # define list of all api calls to be made\n",
    "    api_calls = [\n",
    "        (f'http://{host}/api/v1/data?chart={chart}&after={after}&before={before}&points={points}&format=json&group={group}', chart, host)\n",
    "        for host in hosts for chart in charts\n",
    "    ] \n",
    "    # get the data\n",
    "    df = trio.run(get_charts, api_calls, col_sep, timeout)\n",
    "    # post process the data\n",
    "    if len(hosts) == 1:\n",
    "        df = df.reset_index(level=0, drop=True)\n",
    "    if numeric_only:\n",
    "        df = df._get_numeric_data()\n",
    "    if ffill:\n",
    "        df = df.ffill()\n",
    "    if diff:\n",
    "        df = df.diff().dropna(how='all')\n",
    "    if nunique_thold:\n",
    "        df = drop_low_uniqueness_cols(df, nunique_thold)\n",
    "    if std_thold:\n",
    "        df = drop_low_std_cols(df, std_thold)\n",
    "    if index_as_datetime:\n",
    "        df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df.index, unit='s'), freq=freq))\n",
    "    if sort_cols:\n",
    "        df = df.reindex(sorted(df.columns), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 505)\n",
      "            apps.cpu_system|apps.plugin  apps.cpu_system|charts.d.plugin  \\\n",
      "time_idx                                                                   \n",
      "1601980900                          NaN                              NaN   \n",
      "1601980904                          NaN                              NaN   \n",
      "1601980905                       0.8541                              0.0   \n",
      "1601980906                       0.7204                              0.0   \n",
      "1601980907                       0.0000                              0.0   \n",
      "\n",
      "            apps.cpu_system|httpd  apps.cpu_system|kernel  \\\n",
      "time_idx                                                    \n",
      "1601980900                    NaN                     NaN   \n",
      "1601980904                    NaN                     NaN   \n",
      "1601980905                 0.8508                   0.000   \n",
      "1601980906                 0.0000                   0.000   \n",
      "1601980907                 0.0000                   0.996   \n",
      "\n",
      "            apps.cpu_system|ksmd  apps.cpu_system|netdata  \\\n",
      "time_idx                                                    \n",
      "1601980900                   NaN                      NaN   \n",
      "1601980904                   NaN                      NaN   \n",
      "1601980905                   0.0                   1.7083   \n",
      "1601980906                   0.0                   0.7204   \n",
      "1601980907                   0.0                   0.0000   \n",
      "\n",
      "            apps.cpu_system|python.d.plugin  apps.cpu_system|sql  \\\n",
      "time_idx                                                           \n",
      "1601980900                              NaN                  NaN   \n",
      "1601980904                              NaN                  NaN   \n",
      "1601980905                              0.0                0.000   \n",
      "1601980906                              0.0                0.000   \n",
      "1601980907                              0.0                0.996   \n",
      "\n",
      "            apps.cpu_system|tc-qos-helper  apps.cpu_system|vpn  ...  \\\n",
      "time_idx                                                        ...   \n",
      "1601980900                            NaN                  NaN  ...   \n",
      "1601980904                            NaN                  NaN  ...   \n",
      "1601980905                         0.0000                0.000  ...   \n",
      "1601980906                         0.7204                0.000  ...   \n",
      "1601980907                         0.0000                0.996  ...   \n",
      "\n",
      "            web_log_nginx.requests_per_url|charts  \\\n",
      "time_idx                                            \n",
      "1601980900                                    NaN   \n",
      "1601980904                               8.998841   \n",
      "1601980905                               8.865876   \n",
      "1601980906                               7.732038   \n",
      "1601980907                               6.269853   \n",
      "\n",
      "            web_log_nginx.requests_per_url|kickstart  \\\n",
      "time_idx                                               \n",
      "1601980900                                       NaN   \n",
      "1601980904                                       0.0   \n",
      "1601980905                                       0.0   \n",
      "1601980906                                       0.0   \n",
      "1601980907                                       0.0   \n",
      "\n",
      "            web_log_nginx.requests_per_url|other  \\\n",
      "time_idx                                           \n",
      "1601980900                                   NaN   \n",
      "1601980904                              1.999742   \n",
      "1601980905                              1.866559   \n",
      "1601980906                              1.265757   \n",
      "1601980907                              2.867962   \n",
      "\n",
      "            web_log_nginx.requests_per_url|registry  \\\n",
      "time_idx                                              \n",
      "1601980900                                      NaN   \n",
      "1601980904                                      0.0   \n",
      "1601980905                                      0.0   \n",
      "1601980906                                      0.0   \n",
      "1601980907                                      0.0   \n",
      "\n",
      "            web_log_nginx.response_codes|2xx  \\\n",
      "time_idx                                       \n",
      "1601980900                               NaN   \n",
      "1601980904                         10.998583   \n",
      "1601980905                         10.732435   \n",
      "1601980906                          8.997795   \n",
      "1601980907                          9.137815   \n",
      "\n",
      "            web_log_nginx.response_codes|4xx  \\\n",
      "time_idx                                       \n",
      "1601980900                               NaN   \n",
      "1601980904                               0.0   \n",
      "1601980905                               0.0   \n",
      "1601980906                               0.0   \n",
      "1601980907                               0.0   \n",
      "\n",
      "            web_log_nginx.response_statuses|bad  \\\n",
      "time_idx                                          \n",
      "1601980900                                  NaN   \n",
      "1601980904                                  0.0   \n",
      "1601980905                                  0.0   \n",
      "1601980906                                  0.0   \n",
      "1601980907                                  0.0   \n",
      "\n",
      "            web_log_nginx.response_statuses|success  \\\n",
      "time_idx                                              \n",
      "1601980900                                      NaN   \n",
      "1601980904                                10.998583   \n",
      "1601980905                                10.732435   \n",
      "1601980906                                 8.997795   \n",
      "1601980907                                 9.137815   \n",
      "\n",
      "            web_log_nginx.response_time|avg  web_log_nginx.response_time|max  \n",
      "time_idx                                                                      \n",
      "1601980900                              NaN                              NaN  \n",
      "1601980904                         0.593600                         1.266558  \n",
      "1601980905                         0.833028                         2.733215  \n",
      "1601980906                         0.318155                         0.999755  \n",
      "1601980907                         0.285911                         1.000481  \n",
      "\n",
      "[5 rows x 505 columns]\n"
     ]
    }
   ],
   "source": [
    "# examples\n",
    "\n",
    "df = get_data('london.my-netdata.io', 'all', after=-60, before=0, nunique_thold=0.05)\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "# get some test data\n",
    "test_host = 'london.my-netdata.io'\n",
    "test_charts = ['system.cpu', 'system.load']\n",
    "df = get_data(test_host, test_charts, after=-60, before=0, col_sep='|')\n",
    "\n",
    "# look for some expected columns\n",
    "assert 'system.load|load1' in df.columns\n",
    "assert 'system.cpu|user' in df.columns\n",
    "# check expected shape of data\n",
    "assert str(df.shape) == '(60, 12)' or '(61, 12)'\n",
    "# check that all types are float64 or int64\n",
    "assert len(df.dtypes[df.dtypes != 'int64'][df.dtypes != 'float64']) == 0\n",
    "\n",
    "# test index as datetime\n",
    "df = get_data('london.my-netdata.io', 'system.cpu', index_as_datetime=True)\n",
    "assert isinstance(df.index, pd.core.indexes.datetimes.DatetimeIndex)\n",
    "assert isinstance(df.index.freq, pd.tseries.offsets.Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_alarm_log(host: str = '127.0.0.1:19999', datetimes: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Get alarm log from `host`.  \n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **host** `str` The host we want to get the alarm log from.\n",
    "    \n",
    "    ##### Returns:  \n",
    "    - **df** `pd.DataFrame` A df of the alarm_log.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"http://{host}/api/v1/alarm_log\"\n",
    "    r = requests.get(url)\n",
    "    alarm_log = r.json()\n",
    "    df = pd.DataFrame(alarm_log)\n",
    "    if datetimes:\n",
    "        for col in ['when', 'delay_up_to_timestamp']:\n",
    "            df[col] = pd.to_datetime(df[col], unit='s')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests \n",
    "\n",
    "df = get_alarm_log('london.my-netdata.io')\n",
    "\n",
    "expected_cols = ['hostname', 'unique_id', 'alarm_id', 'alarm_event_id', 'name', 'chart', 'family', 'processed', 'updated', 'exec_run', 'exec_failed', 'exec', 'recipient', 'exec_code', 'source', 'units', 'when', 'duration', 'non_clear_duration', 'status', 'old_status', 'delay', 'delay_up_to_timestamp', 'updated_by_id', 'updates_id', 'value_string', 'old_value_string', 'last_repeat', 'silenced', 'info', 'value', 'old_value', 'no_clear_notification']\n",
    "\n",
    "assert list(df.columns) == expected_cols\n",
    "assert len(df) >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "# test grouping behaves as expected\n",
    "\n",
    "# get some test data\n",
    "test_host = 'london.my-netdata.io'\n",
    "test_charts = ['system.load']\n",
    "\n",
    "# get raw data\n",
    "df_last100 = get_data(test_host, test_charts, after=-100, before=0, col_sep='|')\n",
    "\n",
    "# direclty get aggregations\n",
    "df_avg = get_data(test_host, test_charts, after=-100, before=0, col_sep='|', points=1, group='average')\n",
    "df_std = get_data(test_host, test_charts, after=-100, before=0, col_sep='|', points=1, group='stddev')\n",
    "df_min = get_data(test_host, test_charts, after=-100, before=0, col_sep='|', points=1, group='min')\n",
    "df_max = get_data(test_host, test_charts, after=-100, before=0, col_sep='|', points=1, group='max')\n",
    "\n",
    "# calc by hand\n",
    "df_last100_avg = df_last100.mean()\n",
    "df_last100_std = df_last100.std()\n",
    "df_last100_min = df_last100.min()\n",
    "df_last100_max = df_last100.max()\n",
    "\n",
    "# get diffs\n",
    "avg_diffs = round(abs(df_avg - df_last100_avg), 2)\n",
    "std_diffs = round(abs(df_std - df_last100_std), 2)\n",
    "min_diffs = round(abs(df_min - df_last100_min), 2)\n",
    "max_diffs = round(abs(df_max - df_last100_max), 2)\n",
    "\n",
    "# assert abs differences are small\n",
    "tolerance = 0.1\n",
    "assert (avg_diffs <= tolerance).values.tolist() == [[True, True, True]]\n",
    "assert (std_diffs <= tolerance).values.tolist() == [[True, True, True]]\n",
    "assert (min_diffs <= tolerance).values.tolist() == [[True, True, True]]\n",
    "assert (max_diffs <= tolerance).values.tolist() == [[True, True, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_allmetrics(host, charts: list = None, wide: bool = False, col_sep: str = '|', sort_cols: bool = True):\n",
    "    \"\"\"Get allmetrics into a df.  \n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **host** `str` The host we want to get the alarm log from.\n",
    "    - **charts** `list` A list of charts to pull data for.\n",
    "    - **wide** `bool` True if you want to return the data in wide format as opposed to long.\n",
    "    \n",
    "    ##### Returns:  \n",
    "    - **df** `pd.DataFrame` A df of the latest data from allmetrics.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url = f'http://{host}/api/v1/allmetrics?format=json'\n",
    "    raw_data = requests.get(url).json()\n",
    "    if charts is None:\n",
    "        charts = list(raw_data.keys())\n",
    "    data = []\n",
    "    for k in raw_data:\n",
    "        if k in charts:\n",
    "            time = raw_data[k]['last_updated']\n",
    "            dimensions = raw_data[k]['dimensions']\n",
    "            for dimension in dimensions:\n",
    "                # [time, chart, name, value]\n",
    "                data.append(\n",
    "                    [time, k, \"{}.{}\".format(k, dimensions[dimension]['name']), dimensions[dimension]['value']]\n",
    "                )\n",
    "    df = pd.DataFrame(data, columns=['time','chart','dimension','value'])\n",
    "    if wide:\n",
    "        df['key'] = df['chart'] + col_sep + df['dimension']\n",
    "        df = df[['key', 'value']].groupby('key').mean().reset_index().pivot_table(columns=['key'])\n",
    "        if sort_cols:\n",
    "            df = df.reindex(sorted(df.columns), axis=1)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "host = 'london.my-netdata.io'\n",
    "df = get_allmetrics(host)\n",
    "\n",
    "assert len(df) >= 2000\n",
    "assert list(df.columns) == ['time','chart','dimension','value']\n",
    "assert 'system.cpu' in list(df.chart.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}