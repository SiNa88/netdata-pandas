{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "\n",
    "> Read data from netdata rest api into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# export\n",
    "import asks\n",
    "import trio\n",
    "import pandas as pd\n",
    "import requests\n",
    "from netdata_pandas.wrangle import drop_low_uniqueness_cols, drop_low_std_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_chart_list(host: str = '127.0.0.1:19999', starts_with: str = None) -> list:\n",
    "    \"\"\"Get list of all available charts on a `host`.  \n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **host** `str` The host we want to get a list of available charts from.\n",
    "    - **starts_with** `str` A string to filter the list of charts returns to just those that start with `starts_with`.\n",
    "    \n",
    "    ##### Returns:  \n",
    "    - **chart_list** `list` A list of availalbe charts.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"http://{host}/api/v1/charts\"\n",
    "    r = requests.get(url)\n",
    "    charts = r.json().get('charts')\n",
    "    chart_list = [chart for chart in charts]\n",
    "    if starts_with:\n",
    "        chart_list = [chart for chart in chart_list if chart.startswith(starts_with)]\n",
    "    return chart_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "# get some charts from london demo site\n",
    "charts = get_chart_list('london.my-netdata.io', starts_with='system.')\n",
    "\n",
    "# check just system. charts returned\n",
    "assert set([chart.split('.')[0] for chart in charts]) == set(['system'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "async def get_chart(api_call: str, data: list, col_sep: str ='|'):\n",
    "    \"\"\"Get data for an individual chart.\n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **api_call** `tuple` A tuple of (`url`,`chart`) for the url to pull data from and chart it represents.\n",
    "    - **data** `list` A list for dataframes for each chart to be appended to.\n",
    "    - **col_sep** `str` A character for separating chart and dimension in column names of dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url, chart, host = api_call\n",
    "    r = await asks.get(url)\n",
    "    r_json = r.json()\n",
    "    df = pd.DataFrame(r_json['data'], columns=['time_idx'] + r_json['labels'][1:])\n",
    "    df['host'] = host\n",
    "    df = df.set_index(['host','time_idx']).add_prefix(f'{chart}{col_sep}')\n",
    "    data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "async def get_charts(api_calls: list, col_sep: str ='|', timeout: int = 60) -> pd.DataFrame:\n",
    "    \"\"\"Create a nursey to make seperate async calls to get each chart.\n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **api_calls** `list` A list of tuple's of [(`url`,`chart`),...] of api calls that need to be made.\n",
    "    - **col_sep** `str` A character for separating chart and dimension in column names of dataframe.\n",
    "    - **timeout** `int` The number of seconds for trio to [move_on_after](https://trio.readthedocs.io/en/stable/reference-core.html#trio.move_on_after).\n",
    "    \n",
    "    ##### Returns:  \n",
    "    - **df** `pd.DataFrame` A pandas dataframe with all chart data outer joined based on time index.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    with trio.move_on_after(timeout):\n",
    "        async with trio.open_nursery() as nursery:\n",
    "            for api_call in api_calls:\n",
    "                nursery.start_soon(get_chart, api_call, data, col_sep)\n",
    "    df = pd.concat(data, join='outer', axis=1, sort=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_data(hosts: list = ['london.my-netdata.io'], charts: list = ['system.cpu'], after: int = -60, \n",
    "             before: int = 0, points: int = 0, col_sep: str = '|', numeric_only: bool = False,\n",
    "             ffill: bool = True, diff: bool = False, timeout: int = 60, nunique_thold = None, \n",
    "             std_thold: float = None, index_as_datetime: bool = False, freq: str = 'infer', group: str = 'average') -> pd.DataFrame:\n",
    "    \"\"\"Define api calls to make and any post processing to be done.\n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **hosts** `list` A list of hosts to pull data from.\n",
    "    - **charts** `list` A list of charts to pull data for.\n",
    "    - **after** `int` The timestamp or relative integer from which to pull data after.\n",
    "    - **before** `int` The timestamp or relative integer from which to pull data before.\n",
    "    - **points** `int` The `points` parameter to pass to the api call if need to aggregate data in some way.\n",
    "    - **col_sep** `str` A character for separating chart and dimension in column names of dataframe.\n",
    "    - **numeric_only** `bool` Set to true if you want to filter out any non numeric data.\n",
    "    - **ffill** `bool` Set to true if you want to forward fill any null or missing values.\n",
    "    - **diff** `bool` Set to true if you want to get the difference of metrics as opposed to their raw value.\n",
    "    - **timeout** `int` The number of seconds for trio to [move_on_after](https://trio.readthedocs.io/en/stable/reference-core.html#trio.move_on_after).\n",
    "    - **nunique_thold** [`float`,`int`] If defined calls function to filter cols with low number of unique values.\n",
    "    - **std_thold** `float` If defined calls function to filter cols with low standard deviation.\n",
    "    - **index_as_datetime** `bool` If true, set the index to be a pandas datetime.\n",
    "    - **freq** `str` Freq to be passed to pandas datetime index.\n",
    "    - **group** `str` The grouping function to use.\n",
    "    \n",
    "        \n",
    "    ##### Returns:  \n",
    "    - **df** `pd.DataFrame` A pandas dataframe with all chart data outer joined based on time index and any post processing done.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # if hosts is a string make it a list of one\n",
    "    if isinstance(hosts, str):\n",
    "        hosts = [hosts]\n",
    "        \n",
    "    # if charts is a string make it a list of one\n",
    "    if isinstance(charts, str):\n",
    "        # if specified get all charts\n",
    "        if charts == 'all':\n",
    "            charts = get_chart_list(hosts[0])\n",
    "        else:\n",
    "            charts = [charts]\n",
    "        \n",
    "    \n",
    "    # define list of all api calls to be made\n",
    "    api_calls = [\n",
    "        (f'http://{host}/api/v1/data?chart={chart}&after={after}&before={before}&points={points}&format=json&group={group}', chart, host)\n",
    "        for host in hosts for chart in charts\n",
    "    ] \n",
    "    # get the data\n",
    "    df = trio.run(get_charts, api_calls, col_sep, timeout)\n",
    "    # post process the data\n",
    "    if len(hosts) == 1:\n",
    "        df = df.reset_index(level=0, drop=True)\n",
    "    if numeric_only:\n",
    "        df = df._get_numeric_data()\n",
    "    if ffill:\n",
    "        df = df.ffill()\n",
    "    if diff:\n",
    "        df = df.diff().dropna(how='all')\n",
    "    if nunique_thold:\n",
    "        df = drop_low_uniqueness_cols(df, nunique_thold)\n",
    "    if std_thold:\n",
    "        df = drop_low_std_cols(df, std_thold)\n",
    "    if index_as_datetime:\n",
    "        df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df.index, unit='s'), freq=freq))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 561)\n",
      "            web_log_nginx.requests_per_ipproto|ipv4  \\\n",
      "time_idx                                              \n",
      "1601567878                                14.785464   \n",
      "1601567879                                15.000283   \n",
      "1601567880                                16.854500   \n",
      "1601567881                                12.362195   \n",
      "1601567882                                 9.216069   \n",
      "\n",
      "            web_log_nginx.requests_per_ipproto|ipv6  \\\n",
      "time_idx                                              \n",
      "1601567878                                 0.072620   \n",
      "1601567879                                 2.782863   \n",
      "1601567880                                 2.999870   \n",
      "1601567881                                 0.217268   \n",
      "1601567882                                 0.000000   \n",
      "\n",
      "            nginx_local.connections_accepted_handled|accepted  \\\n",
      "time_idx                                                        \n",
      "1601567878                                                NaN   \n",
      "1601567879                                           1.071683   \n",
      "1601567880                                           3.785286   \n",
      "1601567881                                           1.214651   \n",
      "1601567882                                           0.999962   \n",
      "\n",
      "            nginx_local.connections_accepted_handled|handled  \\\n",
      "time_idx                                                       \n",
      "1601567878                                               NaN   \n",
      "1601567879                                          1.071683   \n",
      "1601567880                                          3.785286   \n",
      "1601567881                                          1.214651   \n",
      "1601567882                                          0.999962   \n",
      "\n",
      "            netdata.runtime_web_log_nginx|run time  \\\n",
      "time_idx                                             \n",
      "1601567878                                     3.0   \n",
      "1601567879                                     3.0   \n",
      "1601567880                                     4.0   \n",
      "1601567881                                     3.0   \n",
      "1601567882                                     2.0   \n",
      "\n",
      "            netdata.web_thread2_cpu|user  netdata.web_thread2_cpu|system  \\\n",
      "time_idx                                                                   \n",
      "1601567878                           NaN                             NaN   \n",
      "1601567879                      0.000000                        1.448259   \n",
      "1601567880                      4.442824                        2.551741   \n",
      "1601567881                      7.586024                        2.014424   \n",
      "1601567882                      3.971152                        1.985576   \n",
      "\n",
      "            netdata.runtime_ntpd_local|run time  \\\n",
      "time_idx                                          \n",
      "1601567878                                  NaN   \n",
      "1601567879                                  3.0   \n",
      "1601567880                                  4.0   \n",
      "1601567881                                  3.0   \n",
      "1601567882                                  2.0   \n",
      "\n",
      "            netdata.runtime_dockerhub|run time  netdata.web_thread1_cpu|user  \\\n",
      "time_idx                                                                       \n",
      "1601567878                                 NaN                           NaN   \n",
      "1601567879                                 NaN                      0.000000   \n",
      "1601567880                              1548.0                      0.000000   \n",
      "1601567881                              1548.0                      0.000000   \n",
      "1601567882                              1548.0                      1.942678   \n",
      "\n",
      "            ...  services.mem_usage|netdata  services.mem_usage|mariadb  \\\n",
      "time_idx    ...                                                           \n",
      "1601567878  ...                         NaN                         NaN   \n",
      "1601567879  ...                         NaN                         NaN   \n",
      "1601567880  ...                    2240.207                    63.84766   \n",
      "1601567881  ...                    2240.578                    63.84766   \n",
      "1601567882  ...                    2240.613                    63.87109   \n",
      "\n",
      "            disk_ops.vda|writes  netdata.db_points|read  \\\n",
      "time_idx                                                  \n",
      "1601567878                  NaN                     NaN   \n",
      "1601567879                  NaN                     NaN   \n",
      "1601567880             -0.65437               16432.314   \n",
      "1601567881              0.00000               19104.770   \n",
      "1601567882              0.00000                6530.594   \n",
      "\n",
      "            netdata.db_points|generated  disk.vda|writes  services.cpu|nginx  \\\n",
      "time_idx                                                                       \n",
      "1601567878                          NaN              NaN                 NaN   \n",
      "1601567879                          NaN              NaN                 NaN   \n",
      "1601567880                   -15790.752       -13.087271            0.327470   \n",
      "1601567881                   -19104.770         0.000000            0.672671   \n",
      "1601567882                    -6530.594         0.000000            0.327329   \n",
      "\n",
      "            services.cpu|gvpe  services.cpu|netdata  services.cpu|mariadb  \n",
      "time_idx                                                                   \n",
      "1601567878                NaN                   NaN                   NaN  \n",
      "1601567879                NaN                   NaN                   NaN  \n",
      "1601567880                0.0              3.654270              0.999776  \n",
      "1601567881                0.0              4.346438              0.327694  \n",
      "1601567882                0.0              4.325763              0.000000  \n",
      "\n",
      "[5 rows x 561 columns]\n"
     ]
    }
   ],
   "source": [
    "# examples\n",
    "\n",
    "df = get_data('london.my-netdata.io', 'all', after=-60, before=0, nunique_thold=0.05)\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "# get some test data\n",
    "test_host = 'london.my-netdata.io'\n",
    "test_charts = ['system.cpu', 'system.load']\n",
    "df = get_data(test_host, test_charts, after=-60, before=0, col_sep='|')\n",
    "\n",
    "# look for some expected columns\n",
    "assert 'system.load|load1' in df.columns\n",
    "assert 'system.cpu|user' in df.columns\n",
    "# check expected shape of data\n",
    "assert str(df.shape) == '(60, 12)' or '(61, 12)'\n",
    "# check that all types are float64 or int64\n",
    "assert len(df.dtypes[df.dtypes != 'int64'][df.dtypes != 'float64']) == 0\n",
    "\n",
    "# test index as datetime\n",
    "df = get_data('london.my-netdata.io', 'system.cpu', index_as_datetime=True)\n",
    "assert isinstance(df.index, pd.core.indexes.datetimes.DatetimeIndex)\n",
    "assert isinstance(df.index.freq, pd.tseries.offsets.Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_alarm_log(host: str = '127.0.0.1:19999', datetimes: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Get alarm log from `host`.  \n",
    "    \n",
    "    ##### Parameters:  \n",
    "    - **host** `str` The host we want to get the alarm log from.\n",
    "    \n",
    "    ##### Returns:  \n",
    "    - **df** `pd.DataFrame` A df of the alarm_log.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"http://{host}/api/v1/alarm_log\"\n",
    "    r = requests.get(url)\n",
    "    alarm_log = r.json()\n",
    "    df = pd.DataFrame(alarm_log)\n",
    "    if datetimes:\n",
    "        for col in ['when', 'delay_up_to_timestamp']:\n",
    "            df[col] = pd.to_datetime(df[col], unit='s')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests \n",
    "\n",
    "df = get_alarm_log('london.my-netdata.io')\n",
    "\n",
    "expected_cols = ['hostname', 'unique_id', 'alarm_id', 'alarm_event_id', 'name', 'chart', 'family', 'processed', 'updated', 'exec_run', 'exec_failed', 'exec', 'recipient', 'exec_code', 'source', 'units', 'when', 'duration', 'non_clear_duration', 'status', 'old_status', 'delay', 'delay_up_to_timestamp', 'updated_by_id', 'updates_id', 'value_string', 'old_value_string', 'last_repeat', 'silenced', 'info', 'value', 'old_value', 'no_clear_notification']\n",
    "\n",
    "assert list(df.columns) == expected_cols\n",
    "assert len(df) >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "# test grouping behaves as expected\n",
    "\n",
    "# get some test data\n",
    "test_host = 'london.my-netdata.io'\n",
    "test_charts = ['system.load']\n",
    "\n",
    "# get raw data\n",
    "df_last100 = get_data(test_host, test_charts, after=-100, before=0, col_sep='|')\n",
    "\n",
    "# direclty get aggregations\n",
    "df_avg = get_data(test_host, test_charts, after=-100, before=0, col_sep='|', points=1, group='average')\n",
    "df_std = get_data(test_host, test_charts, after=-100, before=0, col_sep='|', points=1, group='stddev')\n",
    "df_min = get_data(test_host, test_charts, after=-100, before=0, col_sep='|', points=1, group='min')\n",
    "df_max = get_data(test_host, test_charts, after=-100, before=0, col_sep='|', points=1, group='max')\n",
    "\n",
    "# calc by hand\n",
    "df_last100_avg = df_last100.mean()\n",
    "df_last100_std = df_last100.std()\n",
    "df_last100_min = df_last100.min()\n",
    "df_last100_max = df_last100.max()\n",
    "\n",
    "# get diffs\n",
    "avg_diffs = round(abs(df_avg - df_last100_avg), 2)\n",
    "std_diffs = round(abs(df_std - df_last100_std), 2)\n",
    "min_diffs = round(abs(df_min - df_last100_min), 2)\n",
    "max_diffs = round(abs(df_max - df_last100_max), 2)\n",
    "\n",
    "# assert abs differences are small\n",
    "tolerance = 0.1\n",
    "assert (avg_diffs <= tolerance).values.tolist() == [[True, True, True]]\n",
    "assert (std_diffs <= tolerance).values.tolist() == [[True, True, True]]\n",
    "assert (min_diffs <= tolerance).values.tolist() == [[True, True, True]]\n",
    "assert (max_diffs <= tolerance).values.tolist() == [[True, True, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
